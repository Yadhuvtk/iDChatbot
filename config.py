"""
Central configuration for SOP Chatbot (V5 â€” Accuracy-First).
All tunable parameters in one place.
"""
import os

# â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
SOP_DATA_FILE = os.path.join(DATA_DIR, "sop_data.json")
RAW_DATA_FILE = os.path.join(DATA_DIR, "data.txt")
FAISS_INDEX_FILE = os.path.join(DATA_DIR, "sop_index.faiss")
ID_MAP_FILE = os.path.join(DATA_DIR, "id_map.json")

# V5 new index/model files
BM25_INDEX_FILE = os.path.join(DATA_DIR, "bm25_index.pkl")
FUSION_MODEL_FILE = os.path.join(DATA_DIR, "fusion_model.pkl")
CALIBRATOR_FILE = os.path.join(DATA_DIR, "calibrator.pkl")

# â”€â”€ Hardware Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”€â”€ Hardware Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import torch
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ–¥ï¸  Using device: {DEVICE}")

# â”€â”€ Embedding Model (V5: Single Strong Retriever) â”€â”€â”€â”€â”€
# Check for local manual download first
LOCAL_MODEL_PATH = os.path.join(BASE_DIR, "models", "bge-m3")
if os.path.exists(LOCAL_MODEL_PATH):
    EMBEDDING_MODEL = LOCAL_MODEL_PATH
    print(f"ğŸ“‚ Using local embedding model: {EMBEDDING_MODEL}")
else:
    # BGE-M3: dense + sparse in one model (downloads from HF)
    EMBEDDING_MODEL = "BAAI/bge-m3"
RERANKER_NAME = "cross-encoder/ms-marco-MiniLM-L-6-v2"
EMBEDDING_DIM = 1024  # BGE-M3 dense dimension

# Prefix for BGE queries (used by fallback mode)
QUERY_PREFIX = "Represent this sentence for searching relevant passages: "

# â”€â”€ Retrieval (V5) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SIMILARITY_THRESHOLD = 0.45   # Adaptive fallback (calibrator overrides when trained)
TOP_K_RETRIEVAL = 20          # Candidates for reranking (was 5 in V4)
TOP_K_FINAL = 1               # Final output

# Fusion default weights: [dense, sparse, bm25]
FUSION_WEIGHTS = [0.5, 0.2, 0.3]

# â”€â”€ LLM Rewrite (Optional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USE_LLM_REWRITE = True
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_MODEL = "qwen2.5:1.5b"

# â”€â”€ Rejection Message â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REJECTION_MESSAGE = (
    "This question is not covered in the SOP.\n"
    "Please contact HR."
)

# â”€â”€ Web UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
APP_HOST = "0.0.0.0"
APP_PORT = 7860